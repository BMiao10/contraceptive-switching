{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic-app.wynton.ucsf.edu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "\n",
    "#from utils import medswitch\n",
    "#from utils import contraceptives\n",
    "#from utils import openai_query\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(hostname)\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "\n",
    "from dask_jobqueue import SGECluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "i = 0\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=24, \n",
    "                       #cores = 4,\n",
    "                       memory_limit='24gb')\n",
    "client = Client(cluster)\n",
    "\n",
    "# params\n",
    "rwd_output = './assets/data/'\n",
    "\n",
    "def load_register_table(data_asset, table, **kwargs):\n",
    "    return dd.read_parquet(f'/wynton/protected/project/ic/data/parquet/{data_asset}/{table}/', **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load search terms\n",
    "note_text_rdd = load_register_table(\"DEID_CDW\", \"note_text\")\n",
    "\n",
    "note_rdd = note_text_rdd[note_text_rdd[\"note_text\"].str.contains(\"gpt4|gpt3\", case=False)]\n",
    "note_rdd = note_rdd.compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addressdim\t\t\t\t    fmsample\n",
      "allergendim\t\t\t\t    fmshortvariant\n",
      "allergyfact\t\t\t\t    fmtherapy\n",
      "anesthesiarecordattributevaluedim\t    fmtrial\n",
      "anesthesiarecordfact\t\t\t    fmvariantproperty\n",
      "anesthesiaregistrymetricfact\t\t    guarantordim\n",
      "attendingproviderfact\t\t\t    hospitaladmissionattributevaluedim\n",
      "attributedim\t\t\t\t    hospitaladmissionfact\n",
      "billareadim\t\t\t\t    icustayregistrydatamart\n",
      "billingaccountencountermappingfact\t    imagingfact\n",
      "billingaccountfact\t\t\t    immunizationdim\n",
      "billingproceduredim\t\t\t    immunizationeventfact\n",
      "billingproceduresetdim\t\t\t    immunizationsetdim\n",
      "billingtransactionfact\t\t\t    labcomponentdim\n",
      "birthanesthesiabridge\t\t\t    labcomponentresultfact\n",
      "birthattributevaluedim\t\t\t    labdim\n",
      "birthaugmentationbridge\t\t\t    labtestcomponentresultmappingfact\n",
      "birthaugmentationindicationbridge\t    labtestfact\n",
      "birthcervicalripeningbridge\t\t    manually_deidentified_note_concepts\n",
      "birthcesareanindicationbridge\t\t    manually_deidentified_note_metadata\n",
      "birthepisiotomybridge\t\t\t    manually_deidentified_note_text\n",
      "birthfact\t\t\t\t    medicationadministrationfact\n",
      "birthinductionbridge\t\t\t    medicationcodedim\n",
      "birthinductionindicationbridge\t\t    medicationdim\n",
      "birthrupturetypebridge\t\t\t    medicationdispensefact\n",
      "cancerstagingattributevaluedim\t\t    medicationorderfact\n",
      "cancerstagingfact\t\t\t    medicationsetdim\n",
      "careareadim\t\t\t\t    modifierbridge\n",
      "careteamfact\t\t\t\t    modifierdim\n",
      "changedpatdurablekey_crosswalk_withoffsets  note_concepts\n",
      "chiefcomplaintbridge\t\t\t    note_concepts_headings\n",
      "chiefcomplaintdim\t\t\t    note_metadata\n",
      "codedprocedurefact\t\t\t    note_text\n",
      "costcenterdim\t\t\t\t    patdurabledim\n",
      "coveragedim\t\t\t\t    patientattributevaluedim\n",
      "datedim\t\t\t\t\t    patientdeathregistrydimx\n",
      "dentalfindingeventfact\t\t\t    patientdim\n",
      "dentalprocedureeventfact\t\t    patientlocationeventfact\n",
      "departmentdim\t\t\t\t    patientregistryvaluefact\n",
      "departmentsetdim\t\t\t    pharmacydim\n",
      "diagnosisbridge\t\t\t\t    placeofservicedim\n",
      "diagnosisdim\t\t\t\t    pregnancyattributevaluedim\n",
      "diagnosiseventfact\t\t\t    pregnancyfact\n",
      "diagnosissetdim\t\t\t\t    pregnancyregistrydatamart\n",
      "diagnosisterminologydim\t\t\t    proceduredim\n",
      "drgdim\t\t\t\t\t    procedureeventfact\n",
      "drgeventfact\t\t\t\t    procedureorderfact\n",
      "durationdim\t\t\t\t    proceduresetdim\n",
      "edvisitattributevaluedim\t\t    procedureterminologydim\n",
      "edvisitfact\t\t\t\t    procedureterminologysetdim\n",
      "employeedim\t\t\t\t    providerdim\n",
      "encounterattributevaluedim\t\t    referraleventfact\n",
      "encounterfact\t\t\t\t    referralfact\n",
      "encounterfact_0p1percent\t\t    registrymetricdim\n",
      "episodeencountermappingfact\t\t    releaseversioninfo\n",
      "episodefact\t\t\t\t    resourcedim\n",
      "eyeexamfindingfact\t\t\t    standarddim\n",
      "flowsheetrowdim\t\t\t\t    surgicalcasefact\n",
      "flowsheettemplatedim\t\t\t    surgicalprocedureeventfact\n",
      "flowsheetvaluefact\t\t\t    surgicalsupplydim\n",
      "fmcopynumber\t\t\t\t    surgicalsupplyusefact\n",
      "fmgene\t\t\t\t\t    timeofdaydim\n",
      "fmgenealterationproperty\t\t    ucsf500report\n",
      "fmnonhuman\t\t\t\t    ucsf500variant\n",
      "fmrearrangement\t\t\t\t    version\n",
      "fmreport\t\t\t\t    visitattributevaluedim\n",
      "fmreportproperty\t\t\t    visitfact\n"
     ]
    }
   ],
   "source": [
    "!ls /wynton/protected/project/ic/data/parquet/DEID_CDW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contraceptive cohort extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import contraceptives\n",
    "from utils.medswitch import unique_trajectory\n",
    "\n",
    "# params\n",
    "filepath= \"./data/contraceptives/raw\"\n",
    "\n",
    "contraceptives.getMedications(filepath)\n",
    "contraceptives.getDemographics(filepath)\n",
    "contraceptives.addNotes(filepath)\n",
    "contraceptives.finalWeakAnnotations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pt_demographics = pd.read_parquet(\"./data/contraceptives/annotated_pt_demographics.parquet.gzip\")\n",
    "med_values = pd.read_parquet(\"./data/contraceptives/annotated_medications.parquet.gzip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine order of values to put in prompt\n",
    "labels = [\"Intravaginal\", \"Oral\", \"Transdermal\", \"Injectable\", \"Intrauterine\", \"Implant\"]\n",
    "np.random.shuffle(labels)\n",
    "print(labels)\n",
    "#['Injectable', 'Intravaginal', 'Transdermal', 'Intrauterine', 'Oral', 'Implant']\n",
    "\n",
    "### OpenAI querying\n",
    "engine = \"gpt-4\"\n",
    "med_class_name=\"contraceptives\"\n",
    "date = \"2023-11-13\"\n",
    "\n",
    "'''\n",
    "# split into validation/test datasets\n",
    "medswitch.split_validation_test(med_class_name, validation_size=0.05, seed=0)\n",
    "\n",
    "patient split 76 1439\n",
    "valid split (93, 138)\n",
    "test split (1871, 138)\n",
    "'''\n",
    "\n",
    "# Run prompt development set \n",
    "openai_query.prompt_dev(med_class_name, \n",
    "           engine,\n",
    "           date,\n",
    "          sys_config_values = [\"general\",\"specialist\", \"default\" ],\n",
    "           task_config_values = [\"default\",\"manual-function\",],\n",
    "           function_config=None)\n",
    "\n",
    "# Automated evaluation of prompt development set\n",
    "with open(\"./data/contraceptives/raw/contraceptives.json\") as med_file:\n",
    "    med_mapping = json.load(med_file)\n",
    "\n",
    "prompt_dev_df = pd.read_parquet(\"./data/contraceptives/gpt4/validation.parquet.gzip\")\n",
    "contraceptives.evaluate_prompt_dev(prompt_dev_df, \n",
    "                      med_mapping[\"med_class_mapping\"], \n",
    "                      date=date, \n",
    "                      engine=engine,\n",
    "                     average=\"micro\")\n",
    "\n",
    "# The default prompt consistently showed better performance on both medication and reason extraction \n",
    "# and the specialist system configuration showed slightly higher scores on average.\n",
    "\n",
    "# Use GPT4 to extract test set\n",
    "openai_query.gpt4_test_set(med_class_name=med_class_name,\n",
    "              date=date,\n",
    "              engine=engine,\n",
    "              sys_config = \"specialist\",\n",
    "              task_config = \"default\")\n",
    "\n",
    "# Evaluate test\n",
    "test_labels_df = pd.read_parquet(\"./data/contraceptives/gpt4/test.parquet.gzip\")\n",
    "contraceptives.evaluate_test(test_labels_df, \n",
    "              med_mapping[\"med_class_mapping\"],\n",
    "              date,\n",
    "              sys_config=\"specialist\",\n",
    "              task_config=\"default\",\n",
    "              med_class_name=\"contraceptives\",\n",
    "              engine=\"gpt-4\",\n",
    "              average=\"micro\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open source evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wynton/protected/home/ichs/bmiao/anaconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.benchmark.metrics import classification_metrics\n",
    "from utils.medswitch import  map_generic\n",
    "\n",
    "def evaluate_open_source(preds_file,\n",
    "                     labels_file,\n",
    "                     med_mapping,\n",
    "                     average=\"micro\"):\n",
    "    \"\"\"\n",
    "    Wrapper for evaluating open source model predictins against structured label baselines\n",
    "    \"\"\"\n",
    "    pred_df = pd.read_csv(preds_file, index_col=0)\n",
    "    labels_df = pd.read_parquet(labels_file)\n",
    "    \n",
    "    # Extract value\n",
    "    file_name = preds_file.split(\"/\")[-1] \n",
    "    date = file_name.split(\"_\")[0]\n",
    "    model = file_name.split(\"_\")[1]\n",
    "    \n",
    "    # get corresponding labels\n",
    "    pred_df = pred_df.loc[list(labels_df[\"note_deid_note_key\"])]\n",
    "\n",
    "    # evaluate\n",
    "    class_metrics = {}\n",
    "    pred_values = {}\n",
    "    for pred_col, label_col in [(\"new_contraceptive\",\"mapped_med_generic_clean\"), (\"last_contraceptive\",\"prev_medication\")]:\n",
    "        # map values to class \n",
    "        preds = list(pred_df[pred_col])\n",
    "        preds = [None if type(p)!=str else map_generic(p,\n",
    "                                                       med_mapping,\n",
    "                                                       return_value=False) for p in preds]\n",
    "\n",
    "        preds = [\"\" if p is None else \"\" if p==np.nan else \"\" if p==\"None\" else p for p in preds]\n",
    "        \n",
    "        # evaluate and save metrics, predictions, and labels\n",
    "        labels = list(labels_df[label_col])\n",
    "        labels = [\"\" if l is None else \"\" if l==np.nan else \"\" if l==\"None\" else l for l in labels]\n",
    "        class_metrics[label_col] = classification_metrics(preds=preds, \n",
    "                                                          labels=labels,\n",
    "                                                          average=average)\n",
    "        \n",
    "        #class_metrics[\"n\"] = len(labels)\n",
    "        #class_metrics[\"date\"] = date\n",
    "\n",
    "        pred_values[label_col+\"_\"+model] = preds\n",
    "        pred_values[label_col+\"_labels\"] = labels\n",
    "        \n",
    "    # Concatenate and format\n",
    "    eval_dfs = {\"class\":pd.DataFrame(), \"pred_values\":pd.DataFrame()}\n",
    "    for metric_set_name, curr_metrics in zip(eval_dfs, [class_metrics, pred_values]):\n",
    "        all_class_df = eval_dfs[metric_set_name]\n",
    "        curr_class_df = pd.DataFrame.from_dict(curr_metrics, orient=\"index\")\n",
    "        all_class_df = pd.concat([all_class_df, curr_class_df])\n",
    "        eval_dfs[metric_set_name] = all_class_df\n",
    "    \n",
    "    eval_dfs[\"pred_values\"].columns = pred_df.index\n",
    "    return eval_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/contraceptives/open_source/2024-08-31_starling-7b-alpha_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_llama-3-8b-chat-hf_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_gemma-7b-it_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_Meta-Llama-3.1-8B-Instruct_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_starling-7b-beta_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_BioMistral-7B_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_gemma2-9b-it_prompt-dev_responses.csv\n",
      "./data/contraceptives/open_source/2024-08-31_JSL-MedMNX-7B-SFT_prompt-dev_responses.csv\n"
     ]
    }
   ],
   "source": [
    "average = \"micro\"\n",
    "with open(\"./data/contraceptives/raw/contraceptives.json\") as med_file:\n",
    "    med_mapping = json.load(med_file)\n",
    "med_mapping = med_mapping[\"med_class_mapping\"]\n",
    "\n",
    "# Prompt set evaluation\n",
    "all_metrics = []\n",
    "all_responses = pd.DataFrame(columns=[\"note_deid_note_key\"])\n",
    "\n",
    "fdir = \"./data/contraceptives/open_source/*.csv\"\n",
    "fpaths = glob.glob(fdir)\n",
    "fpaths = [f for f in fpaths if \"prompt-dev_responses.csv\" in f]\n",
    "fpaths = ['./data/contraceptives/open_source/2024-08-31_starling-7b-alpha_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_llama-3-8b-chat-hf_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_gemma-7b-it_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/01-27-24_starling-7b-alpha_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_Meta-Llama-3.1-8B-Instruct_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_starling-7b-beta_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_BioMistral-7B_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_gemma2-9b-it_prompt-dev_responses.csv',\n",
    " './data/contraceptives/open_source/2024-08-31_JSL-MedMNX-7B-SFT_prompt-dev_responses.csv']\n",
    "\n",
    "\n",
    "# empties\n",
    "all_metrics_df = pd.DataFrame()\n",
    "all_responses = pd.DataFrame()\n",
    "\n",
    "for file_path in fpaths:\n",
    "    print(file_path)\n",
    "    prompt_metrics = evaluate_open_source(preds_file=file_path,\n",
    "                     labels_file=\"./data/contraceptives/gpt4/validation.parquet.gzip\",\n",
    "                     med_mapping=med_mapping,\n",
    "                                  average=average)\n",
    "    \n",
    "    # extract date, model_task_name\n",
    "    file_name = file_path.split(\"/\")[-1] \n",
    "    date = file_name.split(\"_\")[0]\n",
    "    model = file_name.split(\"_\")[1]\n",
    "    dataset = file_name.split(\"_\")[2]\n",
    "    \n",
    "    # Append all metrics\n",
    "    acc_metrics = prompt_metrics[\"class\"]\n",
    "    acc_metrics[\"dataset\"] = dataset\n",
    "    acc_metrics[\"model\"] = model\n",
    "    acc_metrics[\"date\"] = date\n",
    "    all_metrics_df = pd.concat([all_metrics_df, acc_metrics])\n",
    "    \n",
    "    # Append all repsonses\n",
    "    append_cols = [idx for idx in prompt_metrics[\"pred_values\"].index if idx not in all_responses.index]\n",
    "    all_responses = pd.concat([all_responses, prompt_metrics[\"pred_values\"].loc[append_cols]])\n",
    "    \n",
    "# Add human labels\n",
    "annotated = pd.read_csv(\"./data/contraceptives/annotation/annotated_set_EE.csv\", index_col=0)\n",
    "annotated = annotated[[\"Contraceptive started\", \"Contraceptive stopped\"]]\n",
    "annotated.columns = [\"mapped_med_generic_clean_expert\", \"prev_medication_expert\"]\n",
    "annotated = annotated.replace(np.nan, \"\")\n",
    "annotated = annotated.replace(\"None\", \"\")\n",
    "\n",
    "all_responses = all_responses.T\n",
    "all_responses = all_responses.merge(annotated, left_index=True, right_index=True)\n",
    "\n",
    "# Add human evaluation\n",
    "for model in list(all_metrics_df[\"model\"].unique()):\n",
    "    start_f1 = classification_metrics(list(all_responses[\"mapped_med_generic_clean_expert\"]),\n",
    "                    list(all_responses[f\"mapped_med_generic_clean_{model}\"]),\n",
    "                    average=\"micro\")\n",
    "\n",
    "    stop_f1 = classification_metrics(list(all_responses[\"prev_medication_expert\"]),\n",
    "                        list(all_responses[f\"prev_medication_{model}\"]),\n",
    "                        average=\"micro\")\n",
    "    \n",
    "    human_scores = pd.DataFrame.from_dict({\"mapped_med_generic_clean_expert\":start_f1,\n",
    "                                          \"prev_medication_expert\":stop_f1}, orient=\"index\")\n",
    "    # Add metadata\n",
    "    human_scores[\"model\"] = model\n",
    "    human_scores[\"dataset\"] = dataset\n",
    "    human_scores[\"date\"] = date\n",
    "    \n",
    "    all_metrics_df = pd.concat([all_metrics_df, human_scores])\n",
    "\n",
    "# Save prompt dev evaluation\n",
    "all_responses.to_csv(f\"./data/contraceptives/open_source/{dataset}_evaluated_preds.csv\")\n",
    "all_metrics_df.to_csv(f\"./data/contraceptives/open_source/{dataset}_classification_metrics_micro.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test set evaluation\n",
    "all_metrics = []\n",
    "all_responses = pd.DataFrame(columns=[\"note_deid_note_key\"])\n",
    "\n",
    "fdir = \"./data/contraceptives/open_source/*.csv\"\n",
    "fpaths = glob.glob(fdir)\n",
    "fpaths = [f for f in fpaths if \"test_responses.csv\" in f]\n",
    "\n",
    "fpaths = ['./data/contraceptives/open_source/2024-08-31_starling-7b-beta_test_responses.csv',\n",
    "          './data/contraceptives/open_source/2024-08-31_starling-7b-alpha_test_responses.csv',\n",
    "         './data/contraceptives/open_source/2024-08-31_gemma2-9b-it_test_responses.csv',\n",
    "          './data/contraceptives/open_source/2024-08-31_BioMistral-7B_test_responses.csv',\n",
    "          './data/contraceptives/open_source/2024-08-31_JSL-MedMNX-7B-SFT_test_responses.csv',\n",
    "         './data/contraceptives/open_source/2024-08-31_Meta-Llama-3.1-8B-Instruct_test_responses.csv',]\n",
    "\n",
    "all_metrics_df = pd.DataFrame()\n",
    "all_responses = pd.DataFrame()\n",
    "\n",
    "for file_path in fpaths:\n",
    "    prompt_metrics = evaluate_open_source(preds_file=file_path,\n",
    "                     labels_file=\"./data/contraceptives/gpt4/test.parquet.gzip\",\n",
    "                     med_mapping=med_mapping,\n",
    "                                  average=average)\n",
    "    \n",
    "    # extract date, model_task_name\n",
    "    file_name = file_path.split(\"/\")[-1] \n",
    "    date = file_name.split(\"_\")[0]\n",
    "    model = file_name.split(\"_\")[1]\n",
    "    dataset = file_name.split(\"_\")[2]\n",
    "\n",
    "    # Append all metrics\n",
    "    acc_metrics = prompt_metrics[\"class\"]\n",
    "    acc_metrics[\"dataset\"] = dataset\n",
    "    acc_metrics[\"model\"] = model\n",
    "    acc_metrics[\"date\"] = date\n",
    "    all_metrics_df = pd.concat([all_metrics_df, acc_metrics])\n",
    "    \n",
    "    # Append all repsonses\n",
    "    append_cols = [idx for idx in prompt_metrics[\"pred_values\"].index if idx not in all_responses.index]\n",
    "    all_responses = pd.concat([all_responses, prompt_metrics[\"pred_values\"].loc[append_cols]])\n",
    "    \n",
    "# Save test evaluation\n",
    "all_responses.to_csv(f\"./data/contraceptives/open_source/{dataset}_evaluated_preds.csv\")\n",
    "all_metrics_df.to_csv(f\"./data/contraceptives/open_source/{dataset}_classification_metrics_micro.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthcare",
   "language": "python",
   "name": "healthcare"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
